{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LiwDtYfvZjes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RIcring8ZjcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install dependencies (A2A + ADK + MCP server deps)"
      ],
      "metadata": {
        "id": "CS_3pl1UZwG7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CLrsFYfZMGC",
        "outputId": "eae2f93a-384d-4219-a746-2e394b1880e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m130.3/130.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m260.5/260.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade -q \\\n",
        "  google-genai \\\n",
        "  google-adk==1.9.0 \\\n",
        "  a2a-sdk==0.3.0 \\\n",
        "  python-dotenv \\\n",
        "  aiohttp \\\n",
        "  uvicorn \\\n",
        "  requests \\\n",
        "  nest-asyncio \\\n",
        "  flask \\\n",
        "  flask-cors \\\n",
        "  termcolor \\\n",
        "  pyngrok"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up environment (API key, project, etc.)"
      ],
      "metadata": {
        "id": "Uvsk2p_6Z3fz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys, logging\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# 1) Force use of API key instead of Vertex if you prefer Aistudio key\n",
        "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n",
        "\n",
        "# 2) GCP project/location ‚Äì adjust to your own\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = \"gen-lang-client-0731702882\"\n",
        "os.environ[\"GOOGLE_CLOUD_LOCATION\"] = \"us-central1\"\n",
        "\n",
        "print(\"Environment variables configured:\")\n",
        "print(\"GOOGLE_GENAI_USE_VERTEXAI:\", os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"])\n",
        "print(\"GOOGLE_CLOUD_PROJECT:\", os.environ[\"GOOGLE_CLOUD_PROJECT\"])\n",
        "print(\"GOOGLE_CLOUD_LOCATION:\", os.environ[\"GOOGLE_CLOUD_LOCATION\"])\n",
        "\n",
        "# 3) Google API key + MCP URL from Colab Secrets (pattern from lg_adk_customer_agent)\n",
        "from google.colab import userdata\n",
        "from termcolor import colored\n",
        "\n",
        "try:\n",
        "    GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "    print(colored(\"‚úÖ Google API Key loaded\", \"green\"))\n",
        "except Exception:\n",
        "    print(colored(\"‚ùå GOOGLE_API_KEY not found in secrets\", \"red\"))\n",
        "    print(colored(\"   Please add it in Colab üîë Secrets\", \"yellow\"))\n",
        "    raise\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZH7ywN9HZutO",
        "outputId": "d30f2620-1ab7-49b0-aef7-0a19e1be0c62"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment variables configured:\n",
            "GOOGLE_GENAI_USE_VERTEXAI: FALSE\n",
            "GOOGLE_CLOUD_PROJECT: gen-lang-client-0731702882\n",
            "GOOGLE_CLOUD_LOCATION: us-central1\n",
            "‚úÖ Google API Key loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize the database (using database_setup.py)"
      ],
      "metadata": {
        "id": "vqn12tYjahC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from database_setup import DatabaseSetup\n",
        "\n",
        "db = DatabaseSetup(\"support.db\")\n",
        "\n",
        "db.connect()            # open DB\n",
        "db.create_tables()      # create customers + tickets tables\n",
        "db.create_triggers()    # create updated_at trigger\n",
        "db.insert_sample_data() # insert the sample customers + tickets\n",
        "db.run_sample_queries() # optional: just to see example outputs\n",
        "db.close()              # close DB connection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUp6HaDzZuqU",
        "outputId": "93c8480b-9e84-43aa-e615-9683784b9784"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected to database: support.db\n",
            "Tables created successfully!\n",
            "Triggers created successfully!\n",
            "Sample data inserted successfully!\n",
            "  - 15 customers added\n",
            "  - 25 tickets added\n",
            "\n",
            "============================================================\n",
            "SAMPLE QUERIES\n",
            "============================================================\n",
            "\n",
            "1. All Open Tickets:\n",
            "------------------------------------------------------------\n",
            "  Ticket #1 | John Doe             | HIGH   | Cannot login to account\n",
            "  Ticket #3 | Edward Norton        | HIGH   | Payment processing failing for all transactions\n",
            "  Ticket #8 | Charlie Brown        | MEDIUM | Email notifications not being received\n",
            "  Ticket #10 | George Miller        | MEDIUM | Export to CSV feature broken\n",
            "  Ticket #13 | Michael Scott        | MEDIUM | API rate limiting too restrictive\n",
            "  Ticket #15 | Jane Smith           | LOW    | Feature request: dark mode\n",
            "  Ticket #16 | Bob Johnson          | LOW    | Documentation outdated for API v2\n",
            "  Ticket #18 | Diana Prince         | LOW    | Request for additional language support\n",
            "  Ticket #20 | Isaac Newton         | LOW    | Feature request: export to PDF\n",
            "  Ticket #21 | Julia Roberts        | LOW    | Color scheme suggestion for better contrast\n",
            "  Ticket #24 | Alice Williams       | LOW    | Feature request: integration with Slack\n",
            "  Ticket #25 | Hannah Lee           | LOW    | Suggestion: add keyboard shortcuts\n",
            "\n",
            "2. High Priority Tickets (Any Status):\n",
            "------------------------------------------------------------\n",
            "  Ticket #1 | John Doe             | open        | Cannot login to account\n",
            "  Ticket #2 | Alice Williams       | in_progress | Database connection timeout errors\n",
            "  Ticket #3 | Edward Norton        | open        | Payment processing failing for all transactions\n",
            "  Ticket #4 | Hannah Lee           | in_progress | Critical security vulnerability found\n",
            "  Ticket #5 | Laura Martinez       | resolved    | Website completely down\n",
            "\n",
            "3. Customers with Most Tickets:\n",
            "------------------------------------------------------------\n",
            "  Jane Smith                | jane.smith@example.com         | 3 tickets\n",
            "  Alice Williams            | alice.w@techcorp.com           | 2 tickets\n",
            "  Charlie Brown             | charlie.brown@email.com        | 2 tickets\n",
            "  Diana Prince              | diana.prince@company.org       | 2 tickets\n",
            "  George Miller             | george.m@enterprise.com        | 2 tickets\n",
            "\n",
            "4. Ticket Statistics by Status:\n",
            "------------------------------------------------------------\n",
            "  open            | 12 tickets\n",
            "  resolved        | 7 tickets\n",
            "  in_progress     | 6 tickets\n",
            "\n",
            "5. Ticket Statistics by Priority:\n",
            "------------------------------------------------------------\n",
            "  high            | 5 tickets\n",
            "  medium          | 8 tickets\n",
            "  low             | 12 tickets\n",
            "\n",
            "6. Active Customers with Open Tickets:\n",
            "------------------------------------------------------------\n",
            "  Alice Williams            | alice.w@techcorp.com           | +1-555-0104\n",
            "  Charlie Brown             | charlie.brown@email.com        | +1-555-0105\n",
            "  Diana Prince              | diana.prince@company.org       | +1-555-0106\n",
            "  Edward Norton             | e.norton@business.net          | +1-555-0107\n",
            "  George Miller             | george.m@enterprise.com        | +1-555-0109\n",
            "  Hannah Lee                | hannah.lee@global.com          | +1-555-0110\n",
            "  Isaac Newton              | isaac.n@science.edu            | +1-555-0111\n",
            "  Jane Smith                | jane.smith@example.com         | +1-555-0102\n",
            "  John Doe                  | john.doe@example.com           | +1-555-0101\n",
            "  Julia Roberts             | julia.r@movies.com             | +1-555-0112\n",
            "  Michael Scott             | michael.scott@paper.com        | +1-555-0115\n",
            "\n",
            "7. Disabled Customers:\n",
            "------------------------------------------------------------\n",
            "  Bob Johnson               | bob.johnson@example.com        | +1-555-0103\n",
            "  Fiona Green               | fiona.green@startup.io         | +1-555-0108\n",
            "  Kevin Chen                | kevin.chen@tech.io             | +1-555-0113\n",
            "\n",
            "8. Most Recent Tickets:\n",
            "------------------------------------------------------------\n",
            "  Ticket #1 | John Doe             | open        | high   | Cannot login to account\n",
            "  Ticket #2 | Alice Williams       | in_progress | high   | Database connection timeout errors\n",
            "  Ticket #3 | Edward Norton        | open        | high   | Payment processing failing for all trans\n",
            "  Ticket #4 | Hannah Lee           | in_progress | high   | Critical security vulnerability found\n",
            "  Ticket #5 | Laura Martinez       | resolved    | high   | Website completely down\n",
            "  Ticket #6 | John Doe             | in_progress | medium | Password reset not working\n",
            "  Ticket #7 | Jane Smith           | resolved    | medium | Profile image upload fails\n",
            "  Ticket #8 | Charlie Brown        | open        | medium | Email notifications not being received\n",
            "  Ticket #9 | Diana Prince         | in_progress | medium | Dashboard loading very slowly\n",
            "  Ticket #10 | George Miller        | open        | medium | Export to CSV feature broken\n",
            "\n",
            "9. Customers Without Any Tickets:\n",
            "------------------------------------------------------------\n",
            "  Fiona Green               | fiona.green@startup.io         | disabled\n",
            "  Kevin Chen                | kevin.chen@tech.io             | disabled\n",
            "\n",
            "10. In-Progress Tickets with Customer Details:\n",
            "------------------------------------------------------------\n",
            "  Ticket #2 | Alice Williams       | HIGH  \n",
            "    Email: alice.w@techcorp.com | Phone: +1-555-0104\n",
            "    Issue: Database connection timeout errors\n",
            "\n",
            "  Ticket #4 | Hannah Lee           | HIGH  \n",
            "    Email: hannah.lee@global.com | Phone: +1-555-0110\n",
            "    Issue: Critical security vulnerability found\n",
            "\n",
            "  Ticket #6 | John Doe             | MEDIUM\n",
            "    Email: john.doe@example.com | Phone: +1-555-0101\n",
            "    Issue: Password reset not working\n",
            "\n",
            "  Ticket #9 | Diana Prince         | MEDIUM\n",
            "    Email: diana.prince@company.org | Phone: +1-555-0106\n",
            "    Issue: Dashboard loading very slowly\n",
            "\n",
            "  Ticket #12 | Julia Roberts        | MEDIUM\n",
            "    Email: julia.r@movies.com | Phone: +1-555-0112\n",
            "    Issue: Search functionality returning wrong results\n",
            "\n",
            "  Ticket #22 | Laura Martinez       | LOW   \n",
            "    Email: laura.m@solutions.com | Phone: +1-555-0114\n",
            "    Issue: Request access to beta features\n",
            "\n",
            "============================================================\n",
            "\n",
            "Database connection closed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement MCP server with the required 5 tools"
      ],
      "metadata": {
        "id": "FSMdPkmbb6Nn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I‚Äôll reuse the MCP pattern from lg_mcp_customer_demo, but implement only the tools the assignment wants:\n",
        "\n",
        "- get_customer(customer_id)\n",
        "\n",
        "- list_customers(status, limit)\n",
        "\n",
        "- update_customer(customer_id, data)\n",
        "\n",
        "- create_ticket(customer_id, issue, priority)\n",
        "\n",
        "- get_customer_history(customer_id)"
      ],
      "metadata": {
        "id": "WLyWIBTgb9fv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports and globals"
      ],
      "metadata": {
        "id": "-_q2HCOTcFpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import json\n",
        "import threading\n",
        "import time\n",
        "from typing import Dict, Any, List\n",
        "\n",
        "from flask import Flask, request, Response, jsonify\n",
        "from flask_cors import CORS\n",
        "from termcolor import colored\n",
        "from pyngrok import ngrok\n",
        "from google.colab import userdata\n",
        "\n",
        "DB_PATH = \"support.db\"\n",
        "SERVER_HOST = \"127.0.0.1\"\n",
        "SERVER_PORT = 5000\n",
        "SERVER_URL = f\"http://{SERVER_HOST}:{SERVER_PORT}\"\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "server_thread = None\n",
        "server_running = False"
      ],
      "metadata": {
        "id": "bjFtYqN6Zunq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DB helper"
      ],
      "metadata": {
        "id": "5_t2Wv-icMCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_db_connection():\n",
        "    conn = sqlite3.connect(DB_PATH)\n",
        "    conn.row_factory = sqlite3.Row\n",
        "    return conn"
      ],
      "metadata": {
        "id": "KyJIaPz6ZulR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tool implementations (DB logic)"
      ],
      "metadata": {
        "id": "n_8ITYQdcXwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_customer(customer_id: int) -> Dict[str, Any]:\n",
        "    conn = get_db_connection()\n",
        "    cursor = conn.cursor()\n",
        "    try:\n",
        "        cursor.execute(\"SELECT * FROM customers WHERE id = ?\", (customer_id,))\n",
        "        row = cursor.fetchone()\n",
        "        if not row:\n",
        "            return {\"success\": False, \"error\": f\"Customer {customer_id} not found\"}\n",
        "\n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"customer\": dict(row),\n",
        "        }\n",
        "    finally:\n",
        "        conn.close()\n",
        "\n",
        "\n",
        "def list_customers(status: str = None, limit: int = 10) -> Dict[str, Any]:\n",
        "    conn = get_db_connection()\n",
        "    cursor = conn.cursor()\n",
        "    try:\n",
        "        if status:\n",
        "            cursor.execute(\n",
        "                \"SELECT * FROM customers WHERE status = ? ORDER BY id LIMIT ?\",\n",
        "                (status, limit),\n",
        "            )\n",
        "        else:\n",
        "            cursor.execute(\n",
        "                \"SELECT * FROM customers ORDER BY id LIMIT ?\", (limit,)\n",
        "            )\n",
        "        rows = cursor.fetchall()\n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"customers\": [dict(r) for r in rows],\n",
        "        }\n",
        "    finally:\n",
        "        conn.close()\n",
        "\n",
        "\n",
        "def update_customer(customer_id: int, data: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    if not data:\n",
        "        return {\"success\": False, \"error\": \"No fields provided to update\"}\n",
        "\n",
        "    allowed_fields = {\"name\", \"email\", \"phone\", \"status\"}\n",
        "    updates = []\n",
        "    values = []\n",
        "    for k, v in data.items():\n",
        "        if k in allowed_fields:\n",
        "            updates.append(f\"{k} = ?\")\n",
        "            values.append(v)\n",
        "\n",
        "    if not updates:\n",
        "        return {\"success\": False, \"error\": \"No valid fields to update\"}\n",
        "\n",
        "    conn = get_db_connection()\n",
        "    cursor = conn.cursor()\n",
        "    try:\n",
        "        values.append(customer_id)\n",
        "        cursor.execute(\n",
        "            f\"UPDATE customers SET {', '.join(updates)}, updated_at = CURRENT_TIMESTAMP WHERE id = ?\",\n",
        "            values,\n",
        "        )\n",
        "        conn.commit()\n",
        "\n",
        "        cursor.execute(\"SELECT * FROM customers WHERE id = ?\", (customer_id,))\n",
        "        row = cursor.fetchone()\n",
        "        if not row:\n",
        "            return {\"success\": False, \"error\": f\"Customer {customer_id} not found after update\"}\n",
        "\n",
        "        return {\"success\": True, \"customer\": dict(row)}\n",
        "    finally:\n",
        "        conn.close()\n",
        "\n",
        "\n",
        "def create_ticket(customer_id: int, issue: str, priority: str = \"medium\") -> Dict[str, Any]:\n",
        "    if priority not in (\"low\", \"medium\", \"high\"):\n",
        "        return {\"success\": False, \"error\": \"priority must be low|medium|high\"}\n",
        "\n",
        "    conn = get_db_connection()\n",
        "    cursor = conn.cursor()\n",
        "    try:\n",
        "        # verify customer exists\n",
        "        cursor.execute(\"SELECT id FROM customers WHERE id = ?\", (customer_id,))\n",
        "        if not cursor.fetchone():\n",
        "            return {\"success\": False, \"error\": f\"Customer {customer_id} not found\"}\n",
        "\n",
        "        cursor.execute(\n",
        "            \"\"\"\n",
        "            INSERT INTO tickets (customer_id, issue, status, priority)\n",
        "            VALUES (?, ?, 'open', ?)\n",
        "            \"\"\",\n",
        "            (customer_id, issue, priority),\n",
        "        )\n",
        "        conn.commit()\n",
        "        ticket_id = cursor.lastrowid\n",
        "\n",
        "        cursor.execute(\"SELECT * FROM tickets WHERE id = ?\", (ticket_id,))\n",
        "        row = cursor.fetchone()\n",
        "        return {\"success\": True, \"ticket\": dict(row)}\n",
        "    finally:\n",
        "        conn.close()\n",
        "\n",
        "\n",
        "def get_customer_history(customer_id: int) -> Dict[str, Any]:\n",
        "    conn = get_db_connection()\n",
        "    cursor = conn.cursor()\n",
        "    try:\n",
        "        # basic customer info\n",
        "        cursor.execute(\"SELECT * FROM customers WHERE id = ?\", (customer_id,))\n",
        "        cust = cursor.fetchone()\n",
        "        if not cust:\n",
        "            return {\"success\": False, \"error\": f\"Customer {customer_id} not found\"}\n",
        "\n",
        "        # tickets\n",
        "        cursor.execute(\n",
        "            \"SELECT * FROM tickets WHERE customer_id = ? ORDER BY created_at DESC\",\n",
        "            (customer_id,),\n",
        "        )\n",
        "        tickets = cursor.fetchall()\n",
        "\n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"customer\": dict(cust),\n",
        "            \"tickets\": [dict(t) for t in tickets],\n",
        "        }\n",
        "    finally:\n",
        "        conn.close()"
      ],
      "metadata": {
        "id": "6CfJrVTnZuiP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MCP tool schemas (MCP_TOOLS): This mirrors the MCP_TOOLS block in lg_mcp_customer_demo, but only for our tools."
      ],
      "metadata": {
        "id": "gXJw47B1dtUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MCP_TOOLS: List[Dict[str, Any]] = [\n",
        "    {\n",
        "        \"name\": \"get_customer\",\n",
        "        \"description\": \"Get a single customer by ID.\",\n",
        "        \"inputSchema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"customer_id\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"description\": \"Customer ID (customers.id)\",\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"customer_id\"],\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"list_customers\",\n",
        "        \"description\": \"List customers, optionally filtered by status.\",\n",
        "        \"inputSchema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"status\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"enum\": [\"active\", \"disabled\"],\n",
        "                    \"description\": \"Filter by customer status (optional)\",\n",
        "                },\n",
        "                \"limit\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"minimum\": 1,\n",
        "                    \"maximum\": 100,\n",
        "                    \"default\": 10,\n",
        "                    \"description\": \"Max number of customers to return\",\n",
        "                },\n",
        "            },\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"update_customer\",\n",
        "        \"description\": \"Update an existing customer fields.\",\n",
        "        \"inputSchema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"customer_id\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"description\": \"Target customers.id\",\n",
        "                },\n",
        "                \"data\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"description\": \"Fields to update\",\n",
        "                    \"properties\": {\n",
        "                        \"name\": {\"type\": \"string\"},\n",
        "                        \"email\": {\"type\": \"string\"},\n",
        "                        \"phone\": {\"type\": \"string\"},\n",
        "                        \"status\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"enum\": [\"active\", \"disabled\"],\n",
        "                        },\n",
        "                    },\n",
        "                },\n",
        "            },\n",
        "            \"required\": [\"customer_id\", \"data\"],\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"create_ticket\",\n",
        "        \"description\": \"Create a new support ticket for a customer.\",\n",
        "        \"inputSchema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"customer_id\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"description\": \"customers.id\",\n",
        "                },\n",
        "                \"issue\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Issue description\",\n",
        "                },\n",
        "                \"priority\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"enum\": [\"low\", \"medium\", \"high\"],\n",
        "                    \"default\": \"medium\",\n",
        "                },\n",
        "            },\n",
        "            \"required\": [\"customer_id\", \"issue\"],\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"get_customer_history\",\n",
        "        \"description\": \"Get a customer plus all their tickets.\",\n",
        "        \"inputSchema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"customer_id\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"description\": \"customers.id\",\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"customer_id\"],\n",
        "        },\n",
        "    },\n",
        "]"
      ],
      "metadata": {
        "id": "wN7xtdZCZudV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MCP message handlers (initialize, tools/list, tools/call): Pattern taken directly from lg_mcp_customer_demo"
      ],
      "metadata": {
        "id": "s1z3yUrxeYK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_initialize(message: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    return {\n",
        "        \"jsonrpc\": \"2.0\",\n",
        "        \"id\": message.get(\"id\"),\n",
        "        \"result\": {\n",
        "            \"protocolVersion\": \"2024-11-05\",\n",
        "            \"capabilities\": {\"tools\": {}},\n",
        "            \"serverInfo\": {\n",
        "                \"name\": \"customer-support-mcp-server\",\n",
        "                \"version\": \"1.0.0\",\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "\n",
        "\n",
        "def handle_tools_list(message: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    return {\n",
        "        \"jsonrpc\": \"2.0\",\n",
        "        \"id\": message.get(\"id\"),\n",
        "        \"result\": {\n",
        "            \"tools\": MCP_TOOLS,\n",
        "        },\n",
        "    }\n",
        "\n",
        "\n",
        "def handle_tools_call(message: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    params = message.get(\"params\", {})\n",
        "    tool_name = params.get(\"name\")\n",
        "    arguments = params.get(\"arguments\", {}) or {}\n",
        "\n",
        "    tool_functions = {\n",
        "        \"get_customer\": get_customer,\n",
        "        \"list_customers\": list_customers,\n",
        "        \"update_customer\": update_customer,\n",
        "        \"create_ticket\": create_ticket,\n",
        "        \"get_customer_history\": get_customer_history,\n",
        "    }\n",
        "\n",
        "    if tool_name not in tool_functions:\n",
        "        return {\n",
        "            \"jsonrpc\": \"2.0\",\n",
        "            \"id\": message.get(\"id\"),\n",
        "            \"error\": {\n",
        "                \"code\": -32601,\n",
        "                \"message\": f\"Tool not found: {tool_name}\",\n",
        "            },\n",
        "        }\n",
        "\n",
        "    try:\n",
        "        result = tool_functions[tool_name](**arguments)\n",
        "        return {\n",
        "            \"jsonrpc\": \"2.0\",\n",
        "            \"id\": message.get(\"id\"),\n",
        "            \"result\": {\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"type\": \"text\",\n",
        "                        \"text\": json.dumps(result, indent=2),\n",
        "                    }\n",
        "                ]\n",
        "            },\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"jsonrpc\": \"2.0\",\n",
        "            \"id\": message.get(\"id\"),\n",
        "            \"error\": {\n",
        "                \"code\": -32000,\n",
        "                \"message\": f\"Tool execution error: {str(e)}\",\n",
        "            },\n",
        "        }"
      ],
      "metadata": {
        "id": "rF8Ys3n-aUgv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MCP message dispatcher + Flask /mcp endpoint (with SSE), /health"
      ],
      "metadata": {
        "id": "rEhgeEj3e8G4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_mcp_message(message: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    method = message.get(\"method\")\n",
        "    if method == \"initialize\":\n",
        "        return handle_initialize(message)\n",
        "    elif method == \"tools/list\":\n",
        "        return handle_tools_list(message)\n",
        "    elif method == \"tools/call\":\n",
        "        return handle_tools_call(message)\n",
        "    else:\n",
        "        return {\n",
        "            \"jsonrpc\": \"2.0\",\n",
        "            \"id\": message.get(\"id\"),\n",
        "            \"error\": {\n",
        "                \"code\": -32601,\n",
        "                \"message\": f\"Unsupported method: {method}\",\n",
        "            },\n",
        "        }\n",
        "\n",
        "\n",
        "def create_sse_message(payload: Dict[str, Any]) -> str:\n",
        "    return f\"data: {json.dumps(payload)}\\n\\n\"\n",
        "\n",
        "\n",
        "@app.route(\"/mcp\", methods=[\"POST\"])\n",
        "def mcp_endpoint():\n",
        "    message = request.get_json()\n",
        "\n",
        "    def generate():\n",
        "        try:\n",
        "            print(f\"üì• Received MCP method: {message.get('method')}\")\n",
        "            response = process_mcp_message(message)\n",
        "            yield create_sse_message(response)\n",
        "        except Exception as e:\n",
        "            error_response = {\n",
        "                \"jsonrpc\": \"2.0\",\n",
        "                \"id\": None,\n",
        "                \"error\": {\"code\": -32700, \"message\": f\"Parse error: {str(e)}\"},\n",
        "            }\n",
        "            yield create_sse_message(error_response)\n",
        "\n",
        "    return Response(generate(), mimetype=\"text/event-stream\")\n",
        "\n",
        "\n",
        "@app.route(\"/health\", methods=[\"GET\"])\n",
        "def health_check():\n",
        "    return jsonify(\n",
        "        {\n",
        "            \"status\": \"healthy\",\n",
        "            \"server\": \"customer-support-mcp-server\",\n",
        "            \"version\": \"1.0.0\",\n",
        "        }\n",
        "    )"
      ],
      "metadata": {
        "id": "DjVO_eMAaUdw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start server + ngrok (background thread, same pattern as lg_mcp_customer_demo)"
      ],
      "metadata": {
        "id": "oluIxNWqfQ9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_server():\n",
        "    global server_running\n",
        "    server_running = True\n",
        "    app.run(host=SERVER_HOST, port=SERVER_PORT, debug=False, use_reloader=False)\n",
        "\n",
        "\n",
        "def start_server(use_ngrok: bool = True):\n",
        "    global server_thread, server_running\n",
        "\n",
        "    if server_thread and server_thread.is_alive():\n",
        "        print(colored(\"‚ö†Ô∏è Server already running\", \"yellow\"))\n",
        "        return\n",
        "\n",
        "    print(colored(\"üöÄ Starting MCP server...\", \"cyan\"))\n",
        "    server_thread = threading.Thread(target=run_server, daemon=True)\n",
        "    server_thread.start()\n",
        "\n",
        "    # Wait until /health responds\n",
        "    import requests\n",
        "\n",
        "    for _ in range(30):\n",
        "        try:\n",
        "            r = requests.get(f\"{SERVER_URL}/health\", timeout=1.0)\n",
        "            if r.status_code == 200:\n",
        "                print(colored(f\"‚úÖ MCP server healthy at {SERVER_URL}\", \"green\"))\n",
        "                break\n",
        "        except Exception:\n",
        "            pass\n",
        "        time.sleep(1.0)\n",
        "\n",
        "    # Ngrok\n",
        "    if use_ngrok:\n",
        "        print(colored(\"\\nüåê Setting up ngrok tunnel...\", \"cyan\"))\n",
        "        try:\n",
        "            authtoken = userdata.get(\"NGROK_AUTHTOKEN\")\n",
        "            ngrok.set_auth_token(authtoken)\n",
        "            public_url = ngrok.connect(SERVER_PORT)\n",
        "            public_url = str(public_url)\n",
        "            print(colored(f\"‚úÖ Public URL: {public_url}\", \"green\", attrs=[\"bold\"]))\n",
        "            print(colored(f\"üìç MCP Endpoint: {public_url}/mcp\", \"green\", attrs=[\"bold\"]))\n",
        "            print(colored(f\"üìç Health Check: {public_url}/health\", \"cyan\"))\n",
        "\n",
        "            print(colored(\"\\n‚û°Ô∏è  Save this URL as MCP_SERVER_URL in Colab Secrets\", \"yellow\"))\n",
        "        except Exception as e:\n",
        "            print(colored(\"‚ö†Ô∏è Could not set up ngrok\", \"yellow\"))\n",
        "            print(e)"
      ],
      "metadata": {
        "id": "dP9RzwOneCOm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_server(use_ngrok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebHtzCXqeCL3",
        "outputId": "fe853e19-2c44-4af5-e506-b66c6a247ad4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting MCP server...\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 06:24:26] \"GET /health HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ MCP server healthy at http://127.0.0.1:5000\n",
            "\n",
            "üåê Setting up ngrok tunnel...\n",
            "‚úÖ Public URL: NgrokTunnel: \"https://fd6ec522f674.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            "üìç MCP Endpoint: NgrokTunnel: \"https://fd6ec522f674.ngrok-free.app\" -> \"http://localhost:5000\"/mcp\n",
            "üìç Health Check: NgrokTunnel: \"https://fd6ec522f674.ngrok-free.app\" -> \"http://localhost:5000\"/health\n",
            "\n",
            "‚û°Ô∏è  Save this URL as MCP_SERVER_URL in Colab Secrets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Customer Data Agent (ADK + MCPToolset) = ‚ÄúCustomer Data Agent (Specialist)‚Äù: Now I reuse the pattern in lg_adk_customer_agent, but be explicit that this agent is the Customer Data Agent."
      ],
      "metadata": {
        "id": "RycBRp0Sfz9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from termcolor import colored\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "from google.adk.agents import LlmAgent\n",
        "from google.adk.tools.mcp_tool import MCPToolset, StreamableHTTPConnectionParams\n",
        "\n",
        "MCP_SERVER_URL = userdata.get(\"MCP_SERVER_URL\")\n",
        "print(colored(f\"‚úÖ MCP_SERVER_URL: {MCP_SERVER_URL}\", \"green\"))\n",
        "\n",
        "customer_data_agent = LlmAgent(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    name=\"customer_data_agent\",\n",
        "    description=\"\"\"\n",
        "You are the Customer Data Agent.\n",
        "\n",
        "You ONLY interact with the customer database via MCP tools:\n",
        "- get_customer(customer_id)\n",
        "- list_customers(status, limit)\n",
        "- update_customer(customer_id, data)\n",
        "- create_ticket(customer_id, issue, priority)\n",
        "- get_customer_history(customer_id)\n",
        "\n",
        "Responsibilities:\n",
        "- Retrieve and validate customer data.\n",
        "- Update fields when asked.\n",
        "- Create tickets and return IDs.\n",
        "- Fetch and summarize customer history.\n",
        "\n",
        "Always:\n",
        "- Describe which MCP tools you used.\n",
        "- Return structured summaries that other agents can reuse.\n",
        "\"\"\",\n",
        "    tools=[\n",
        "        MCPToolset(\n",
        "            connection_params=StreamableHTTPConnectionParams(\n",
        "                url=MCP_SERVER_URL\n",
        "            )\n",
        "        )\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(colored(\"üí° Customer Data Agent ready (via MCP).\", \"yellow\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HB5EG40eCJV",
        "outputId": "b1f86457-8f24-4982-c3de-f08418887faa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/cloud/aiplatform/models.py:52: FutureWarning: Support for google-cloud-storage < 3.0.0 will be removed in a future version of google-cloud-aiplatform. Please upgrade to google-cloud-storage >= 3.0.0.\n",
            "  from google.cloud.aiplatform.utils import gcs_utils\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ MCP_SERVER_URL: https://fd6ec522f674.ngrok-free.app/mcp\n",
            "üí° Customer Data Agent ready (via MCP).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Agent (Specialist) ‚Äì general customer support"
      ],
      "metadata": {
        "id": "XUe19wCyht-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.adk.agents import LlmAgent\n",
        "\n",
        "support_agent = LlmAgent(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    name=\"support_agent\",\n",
        "    description=\"\"\"\n",
        "You are the Support Agent.\n",
        "\n",
        "Your responsibilities:\n",
        "- Handle general customer support questions.\n",
        "- For billing, cancellation, or escalation cases, you may need context from the Customer Data Agent (sent via the Router).\n",
        "- You NEVER call MCP tools directly.\n",
        "- You expect the Router to give you the customer information you need.\n",
        "\n",
        "When responding:\n",
        "- Always use the context passed from the Router/Data Agent.\n",
        "- Clearly state when something is urgent or escalated.\n",
        "- Be concise, friendly, and action-oriented.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "print(colored(\"üí° Support Agent ready.\", \"yellow\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwSsirwYfd4U",
        "outputId": "74b1727a-4825-4bbb-d82e-5e4e9b7bb46b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üí° Support Agent ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wrap agents as A2A servers (using LG_a2a_quickstart): Now I directly reuse the A2A server pattern from lg_a2a_quickstart"
      ],
      "metadata": {
        "id": "kZAvWqxEiGxb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import A2A helpers from LG_a2a_quickstart"
      ],
      "metadata": {
        "id": "w_zj91DDiMPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "%pip install --upgrade -q google-genai google-adk==1.9.0 a2a-sdk==0.3.0 python-dotenv aiohttp uvicorn requests mermaid-python nest-asyncio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qwkxo1b3i57m",
        "outputId": "e3c50632-7767-4fa5-db0f-09c2d740615f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.5/1.6 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Targeted workaround for google-adk==1.9.0 compatibility with a2a-sdk==0.3.0\n",
        "# This cell shall be removed when google-adk releases the version next to >1.9.0\n",
        "# (after https://github.com/google/adk-python/pull/2297)\n",
        "\n",
        "\n",
        "import sys\n",
        "\n",
        "from a2a.client import client as real_client_module\n",
        "from a2a.client.card_resolver import A2ACardResolver\n",
        "\n",
        "\n",
        "class PatchedClientModule:\n",
        "    def __init__(self, real_module) -> None:\n",
        "        for attr in dir(real_module):\n",
        "            if not attr.startswith('_'):\n",
        "                setattr(self, attr, getattr(real_module, attr))\n",
        "        self.A2ACardResolver = A2ACardResolver\n",
        "\n",
        "\n",
        "patched_module = PatchedClientModule(real_client_module)\n",
        "sys.modules['a2a.client.client'] = patched_module  # type: ignore"
      ],
      "metadata": {
        "id": "6E2lisNTfd1r"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import threading\n",
        "import time\n",
        "\n",
        "from typing import Any\n",
        "\n",
        "import httpx\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "\n",
        "from a2a.client import ClientConfig, ClientFactory, create_text_message_object\n",
        "from a2a.server.apps import A2AStarletteApplication\n",
        "from a2a.server.request_handlers import DefaultRequestHandler\n",
        "from a2a.server.tasks import InMemoryTaskStore\n",
        "from a2a.types import (\n",
        "    AgentCapabilities,\n",
        "    AgentCard,\n",
        "    AgentSkill,\n",
        "    TransportProtocol,\n",
        ")\n",
        "from a2a.utils.constants import AGENT_CARD_WELL_KNOWN_PATH\n",
        "from dotenv import load_dotenv\n",
        "from google.adk.a2a.executor.a2a_agent_executor import (\n",
        "    A2aAgentExecutor,\n",
        "    A2aAgentExecutorConfig,\n",
        ")\n",
        "from google.adk.agents import Agent, SequentialAgent\n",
        "from google.adk.agents.remote_a2a_agent import RemoteA2aAgent\n",
        "from google.adk.artifacts import InMemoryArtifactService\n",
        "from google.adk.memory.in_memory_memory_service import InMemoryMemoryService\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.tools import google_search"
      ],
      "metadata": {
        "id": "czTVsPk0fdyq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### I‚Äôll copy the helper create_agent_a2a_server pattern (taken from LG_a2a_quickstart):"
      ],
      "metadata": {
        "id": "pv5mljkAjXSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_agent_a2a_server(agent, agent_card):\n",
        "    runner = Runner(\n",
        "        app_name=agent.name,\n",
        "        agent=agent,\n",
        "        artifact_service=InMemoryArtifactService(),\n",
        "        session_service=InMemorySessionService(),\n",
        "        memory_service=InMemoryMemoryService(),\n",
        "    )\n",
        "\n",
        "    config = A2aAgentExecutorConfig()\n",
        "    executor = A2aAgentExecutor(runner=runner, config=config)\n",
        "\n",
        "    request_handler = DefaultRequestHandler(\n",
        "        agent_executor=executor,\n",
        "        task_store=InMemoryTaskStore(),\n",
        "    )\n",
        "\n",
        "    return A2AStarletteApplication(\n",
        "        agent_card=agent_card,\n",
        "        http_handler=request_handler\n",
        "    )\n",
        "\n",
        "\n",
        "async def run_agent_server(agent, agent_card, port: int):\n",
        "    app = create_agent_a2a_server(agent, agent_card)\n",
        "    config = uvicorn.Config(\n",
        "        app.build(),\n",
        "        host=\"127.0.0.1\",\n",
        "        port=port,\n",
        "        log_level=\"warning\",\n",
        "        loop=\"none\",\n",
        "    )\n",
        "    server = uvicorn.Server(config)\n",
        "    await server.serve()"
      ],
      "metadata": {
        "id": "MdG3D0CEfyU5"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define AgentCards and A2A ports"
      ],
      "metadata": {
        "id": "sx5jh1_fj4f0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I‚Äôll run:\n",
        "\n",
        "Customer Data Agent A2A ‚Üí http://127.0.0.1:11020\n",
        "\n",
        "Support Agent A2A ‚Üí http://127.0.0.1:11021\n",
        "\n",
        "Router/Host Agent A2A ‚Üí http://127.0.0.1:11022"
      ],
      "metadata": {
        "id": "NA8AJpCfj6a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customer_data_card = AgentCard(\n",
        "    name=\"Customer Data Agent\",\n",
        "    url=\"http://127.0.0.1:11020\",\n",
        "    description=\"Specialist for customer DB via MCP.\",\n",
        "    version=\"1.0\",\n",
        "    capabilities=AgentCapabilities(streaming=True),\n",
        "    default_input_modes=[\"text/plain\"],\n",
        "    default_output_modes=[\"text/plain\"],\n",
        "    preferred_transport=TransportProtocol.jsonrpc,\n",
        "    skills=[],\n",
        ")\n",
        "\n",
        "support_agent_card = AgentCard(\n",
        "    name=\"Support Agent\",\n",
        "    url=\"http://127.0.0.1:11021\",\n",
        "    description=\"Specialist for general support & escalation.\",\n",
        "    version=\"1.0\",\n",
        "    capabilities=AgentCapabilities(streaming=True),\n",
        "    default_input_modes=[\"text/plain\"],\n",
        "    default_output_modes=[\"text/plain\"],\n",
        "    preferred_transport=TransportProtocol.jsonrpc,\n",
        "    skills=[],\n",
        ")"
      ],
      "metadata": {
        "id": "ZLeNOo8Ajdmy"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Router Agent (Host) as A2A SequentialAgent"
      ],
      "metadata": {
        "id": "CU-W5Ml1kAAg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Router = orchestrator that uses RemoteA2aAgent wrappers, exactly like LG_a2a_quickstart‚Äôs Host Agent pattern."
      ],
      "metadata": {
        "id": "3QulTeKGkDu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remote views of the two specialists\n",
        "remote_customer_data_agent = RemoteA2aAgent(\n",
        "    name=\"customer_data_remote\",\n",
        "    description=\"Calls the Customer Data Agent over A2A.\",\n",
        "    agent_card=f\"http://127.0.0.1:11020{AGENT_CARD_WELL_KNOWN_PATH}\",\n",
        ")\n",
        "\n",
        "remote_support_agent = RemoteA2aAgent(\n",
        "    name=\"support_remote\",\n",
        "    description=\"Calls the Support Agent over A2A.\",\n",
        "    agent_card=f\"http://127.0.0.1:11021{AGENT_CARD_WELL_KNOWN_PATH}\",\n",
        ")\n",
        "\n",
        "# Router / Host orchestrator\n",
        "router_agent = SequentialAgent(\n",
        "    name=\"customer_service_router\",\n",
        "    sub_agents=[remote_customer_data_agent, remote_support_agent],\n",
        ")\n",
        "\n",
        "router_agent_card = AgentCard(\n",
        "    name=\"Customer Service Router\",\n",
        "    url=\"http://127.0.0.1:11022\",\n",
        "    description=(\n",
        "        \"Router that analyzes intent and coordinates between \"\n",
        "        \"Customer Data Agent and Support Agent using A2A.\"\n",
        "    ),\n",
        "    version=\"1.0\",\n",
        "    capabilities=AgentCapabilities(streaming=True),\n",
        "    default_input_modes=[\"text/plain\"],\n",
        "    default_output_modes=[\"text/plain\"],\n",
        "    preferred_transport=TransportProtocol.jsonrpc,\n",
        "    skills=[],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rit46bOmjdkQ",
        "outputId": "7613ae4e-c709-4fe0-e42f-79eff53a0581"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2968627968.py:2: UserWarning: [EXPERIMENTAL] RemoteA2aAgent: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
            "  remote_customer_data_agent = RemoteA2aAgent(\n",
            "/tmp/ipython-input-2968627968.py:8: UserWarning: [EXPERIMENTAL] RemoteA2aAgent: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
            "  remote_support_agent = RemoteA2aAgent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The logic for Scenario 1/2/3 is encoded in the system prompts plus the fact that the router calls the two sub-agents in sequence.\n",
        "\n",
        "I can refine prompts later to be more explicit:\n",
        "\n",
        "if ID present ‚Üí call data first; if billing keywords ‚Üí escalate; if query about lists ‚Üí ask data agent for lists & tickets, etc."
      ],
      "metadata": {
        "id": "qIGj7NjZkQo-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start all three A2A servers (background in the same loop)"
      ],
      "metadata": {
        "id": "ErDVZRwOkaEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import threading\n",
        "import time\n",
        "\n",
        "async def start_all_a2a_servers():\n",
        "    tasks = [\n",
        "        asyncio.create_task(\n",
        "            run_agent_server(customer_data_agent, customer_data_card, 11020)\n",
        "        ),\n",
        "        asyncio.create_task(\n",
        "            run_agent_server(support_agent, support_agent_card, 11021)\n",
        "        ),\n",
        "        asyncio.create_task(\n",
        "            run_agent_server(router_agent, router_agent_card, 11022)\n",
        "        ),\n",
        "    ]\n",
        "\n",
        "    # Give the servers a moment to bind the ports\n",
        "    await asyncio.sleep(2)\n",
        "    print(\"‚úÖ A2A servers started:\")\n",
        "    print(\"   - Customer Data Agent: http://127.0.0.1:11020\")\n",
        "    print(\"   - Support Agent      : http://127.0.0.1:11021\")\n",
        "    print(\"   - Router/Host        : http://127.0.0.1:11022\")\n",
        "\n",
        "    # Keep all three servers running\n",
        "    await asyncio.gather(*tasks)\n",
        "\n",
        "\n",
        "def run_servers_in_background():\n",
        "    \"\"\"Run the A2A servers in their own event loop & thread.\"\"\"\n",
        "    asyncio.run(start_all_a2a_servers())\n",
        "\n",
        "\n",
        "# üîπ Start the servers in a background thread\n",
        "server_thread = threading.Thread(target=run_servers_in_background, daemon=True)\n",
        "server_thread.start()\n",
        "\n",
        "# Small pause so they're ready before first request\n",
        "time.sleep(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ohpnqevfm2rd",
        "outputId": "ad5211fa-a210-4876-ae75-11b347abc5e5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-712332793.py:10: UserWarning: [EXPERIMENTAL] A2aAgentExecutorConfig: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
            "  config = A2aAgentExecutorConfig()\n",
            "/tmp/ipython-input-712332793.py:11: UserWarning: [EXPERIMENTAL] A2aAgentExecutor: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
            "  executor = A2aAgentExecutor(runner=runner, config=config)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ A2A servers started:\n",
            "   - Customer Data Agent: http://127.0.0.1:11020\n",
            "   - Support Agent      : http://127.0.0.1:11021\n",
            "   - Router/Host        : http://127.0.0.1:11022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A2A Client (A2ASimpleClient from LG_a2a_quickstart): I reuse A2ASimpleClient from LG_a2a_quickstart to simulate customer queries."
      ],
      "metadata": {
        "id": "C275znDTkgNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class A2ASimpleClient:\n",
        "    \"\"\"A2A Simple to call A2A servers.\"\"\"\n",
        "\n",
        "    def __init__(self, default_timeout: float = 240.0):\n",
        "        self._agent_info_cache: dict[\n",
        "            str, dict[str, Any] | None\n",
        "        ] = {}  # Cache for agent metadata\n",
        "        self.default_timeout = default_timeout\n",
        "\n",
        "    async def create_task(self, agent_url: str, message: str) -> str:\n",
        "        \"\"\"Send a message following the official A2A SDK pattern.\"\"\"\n",
        "        # Configure httpx client with timeout\n",
        "        timeout_config = httpx.Timeout(\n",
        "            timeout=self.default_timeout,\n",
        "            connect=10.0,\n",
        "            read=self.default_timeout,\n",
        "            write=10.0,\n",
        "            pool=5.0,\n",
        "        )\n",
        "\n",
        "        async with httpx.AsyncClient(timeout=timeout_config) as httpx_client:\n",
        "            # Check if we have cached agent card data\n",
        "            if (\n",
        "                agent_url in self._agent_info_cache\n",
        "                and self._agent_info_cache[agent_url] is not None\n",
        "            ):\n",
        "                agent_card_data = self._agent_info_cache[agent_url]\n",
        "            else:\n",
        "                # Fetch the agent card\n",
        "                agent_card_response = await httpx_client.get(\n",
        "                    f'{agent_url}{AGENT_CARD_WELL_KNOWN_PATH}'\n",
        "                )\n",
        "                agent_card_data = self._agent_info_cache[agent_url] = (\n",
        "                    agent_card_response.json()\n",
        "                )\n",
        "\n",
        "            # Create AgentCard from data\n",
        "            agent_card = AgentCard(**agent_card_data)\n",
        "\n",
        "            # Create A2A client with the agent card\n",
        "            config = ClientConfig(\n",
        "                httpx_client=httpx_client,\n",
        "                supported_transports=[\n",
        "                    TransportProtocol.jsonrpc,\n",
        "                    TransportProtocol.http_json,\n",
        "                ],\n",
        "                use_client_preference=True,\n",
        "            )\n",
        "\n",
        "            factory = ClientFactory(config)\n",
        "            client = factory.create(agent_card)\n",
        "\n",
        "            # Create the message object\n",
        "            message_obj = create_text_message_object(content=message)\n",
        "\n",
        "            # Send the message and collect responses\n",
        "            responses = []\n",
        "            async for response in client.send_message(message_obj):\n",
        "                responses.append(response)\n",
        "\n",
        "            # The response is a tuple - get the first element (Task object)\n",
        "            if (\n",
        "                responses\n",
        "                and isinstance(responses[0], tuple)\n",
        "                and len(responses[0]) > 0\n",
        "            ):\n",
        "                task = responses[0][0]  # First element of the tuple\n",
        "\n",
        "                # Extract text: task.artifacts[0].parts[0].root.text\n",
        "                try:\n",
        "                    return task.artifacts[0].parts[0].root.text\n",
        "                except (AttributeError, IndexError):\n",
        "                    return str(task)\n",
        "\n",
        "            return 'No response received'"
      ],
      "metadata": {
        "id": "ALLfeUpmkYE8"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a2a_client = A2ASimpleClient()"
      ],
      "metadata": {
        "id": "ShLJWoFCkYCE"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROUTER_URL = \"http://127.0.0.1:11022\""
      ],
      "metadata": {
        "id": "-4WDAHkWkX_j"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper:"
      ],
      "metadata": {
        "id": "d1W5rDTMk67C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def ask_router(query: str):\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üë§ USER:\", query)\n",
        "    print(\"=\"*70)\n",
        "    response = await a2a_client.create_task(ROUTER_URL, query)\n",
        "    print(\"\\nü§ñ ROUTER RESPONSE:\")\n",
        "    print(response)"
      ],
      "metadata": {
        "id": "Z41UW0L_fySJ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the required test scenarios"
      ],
      "metadata": {
        "id": "1KJOp7CrlEvr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scenario 1 ‚Äì Task Allocation\n",
        "\n",
        "Query: \"I need help with my account, customer ID 12345\""
      ],
      "metadata": {
        "id": "RZrKVy-flGzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "await ask_router(\"I need help with my account, customer ID 5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-igT27EKk-O4",
        "outputId": "b2e910cd-8f98-448d-95ca-dcc153e80810"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üë§ USER: I need help with my account, customer ID 5\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/adk/a2a/executor/a2a_agent_executor.py:184: UserWarning: [EXPERIMENTAL] convert_a2a_request_to_adk_run_args: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
            "  run_args = convert_a2a_request_to_adk_run_args(context)\n",
            "/usr/local/lib/python3.12/dist-packages/google/adk/a2a/converters/request_converter.py:64: UserWarning: [EXPERIMENTAL] convert_a2a_part_to_genai_part: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
            "  convert_a2a_part_to_genai_part(part)\n",
            "/usr/local/lib/python3.12/dist-packages/google/adk/a2a/executor/a2a_agent_executor.py:214: UserWarning: [EXPERIMENTAL] TaskResultAggregator: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
            "  task_result_aggregator = TaskResultAggregator()\n",
            "/usr/local/lib/python3.12/dist-packages/google/adk/agents/remote_a2a_agent.py:358: UserWarning: [EXPERIMENTAL] convert_genai_part_to_a2a_part: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
            "  converted_part = convert_genai_part_to_a2a_part(part)\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 06:30:24] \"POST /mcp HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 06:30:25] \"POST /mcp HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Received MCP method: initialize\n",
            "üì• Received MCP method: notifications/initialized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 06:30:25] \"POST /mcp HTTP/1.1\" 200 -\n",
            "/usr/local/lib/python3.12/dist-packages/google/adk/tools/mcp_tool/mcp_tool.py:87: UserWarning: [EXPERIMENTAL] BaseAuthenticatedTool: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
            "  super().__init__(\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Received MCP method: tools/list\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "/usr/local/lib/python3.12/dist-packages/google/adk/a2a/executor/a2a_agent_executor.py:216: UserWarning: [EXPERIMENTAL] convert_event_to_a2a_events: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
            "  for a2a_event in convert_event_to_a2a_events(\n",
            "/usr/local/lib/python3.12/dist-packages/google/adk/a2a/converters/event_converter.py:512: UserWarning: [EXPERIMENTAL] convert_event_to_a2a_message: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
            "  message = convert_event_to_a2a_message(event, invocation_context)\n",
            "/usr/local/lib/python3.12/dist-packages/google/adk/a2a/converters/event_converter.py:350: UserWarning: [EXPERIMENTAL] convert_genai_part_to_a2a_part: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
            "  a2a_part = convert_genai_part_to_a2a_part(part)\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 06:30:26] \"POST /mcp HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 06:30:26] \"POST /mcp HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Received MCP method: tools/call\n",
            "üì• Received MCP method: tools/list\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "/usr/local/lib/python3.12/dist-packages/google/adk/a2a/converters/event_converter.py:206: UserWarning: [EXPERIMENTAL] convert_a2a_message_to_event: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
            "  return convert_a2a_message_to_event(message, author, invocation_context)\n",
            "/usr/local/lib/python3.12/dist-packages/google/adk/a2a/converters/event_converter.py:272: UserWarning: [EXPERIMENTAL] convert_a2a_part_to_genai_part: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
            "  part = convert_a2a_part_to_genai_part(a2a_part)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü§ñ ROUTER RESPONSE:\n",
            "Hello Charlie Brown!\n",
            "\n",
            "I have your account details here:\n",
            "*   **Name:** Charlie Brown\n",
            "*   **Email:** charlie.brown@email.com\n",
            "*   **Phone:** +1-555-0105\n",
            "*   **Status:** active\n",
            "\n",
            "How can I help you with your account today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scenario 2 ‚Äì Negotiation / Escalation\n",
        "\n",
        "Query: \"I want to cancel my subscription but I'm having billing issues\""
      ],
      "metadata": {
        "id": "3_YJuo1uqLl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "await ask_router(\"I want to cancel my subscription but I'm having billing issues.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxnev1-Mk-MP",
        "outputId": "74d9700c-aac9-400d-f42d-5555191da887"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üë§ USER: I want to cancel my subscription but I'm having billing issues.\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 06:31:02] \"POST /mcp HTTP/1.1\" 200 -\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Received MCP method: tools/list\n",
            "\n",
            "ü§ñ ROUTER RESPONSE:\n",
            "I understand you're looking to cancel your subscription and are experiencing billing issues. To help you with both of these urgent matters, the Data Agent needs your customer ID. Please provide your customer ID so they can retrieve your account details, and then I can assist you further.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scenario 3 ‚Äì Multi-Step Coordination\n",
        "\n",
        "Query: \"What's the status of all high-priority tickets for premium customers?\""
      ],
      "metadata": {
        "id": "C9ZAyGXpqSNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "await ask_router(\"What's the status of all high-priority tickets for active customers?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtE75E_Ok6io",
        "outputId": "5cb4c1b4-c378-4ef8-e391-d8a307b08815"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üë§ USER: What's the status of all high-priority tickets for active customers?\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 06:31:32] \"POST /mcp HTTP/1.1\" 200 -\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Received MCP method: tools/list\n",
            "\n",
            "ü§ñ ROUTER RESPONSE:\n",
            "I apologize, but I cannot provide the status of high-priority tickets or filter tickets by priority. The customer data system only allows me to list customers and their tickets, but I don't have the functionality to check ticket status or filter them based on priority.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Assignment ‚ÄúTest Scenarios‚Äù 1‚Äì5\n",
        "\n",
        "I can call the same helper:"
      ],
      "metadata": {
        "id": "aw920Mmhqc4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Simple Query\n",
        "await ask_router(\"Get customer information for ID 5\")\n",
        "\n",
        "# 2. Coordinated Query\n",
        "await ask_router(\"I'm customer 5 and need help upgrading my account\")\n",
        "\n",
        "# 3. Complex Query\n",
        "await ask_router(\"Show me all active customers who have open tickets\")\n",
        "\n",
        "# 4. Escalation\n",
        "await ask_router(\"I've been charged twice, please refund immediately!\")\n",
        "\n",
        "# 5. Multi-Intent\n",
        "await ask_router(\"Update my email to new_email@example.com and show my ticket history for customer 5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqYfUH8Lk6gG",
        "outputId": "c3c05485-c516-43b4-9adf-67b1d535a682"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üë§ USER: Get customer information for ID 5\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 06:32:27] \"POST /mcp HTTP/1.1\" 200 -\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Received MCP method: tools/list\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 06:32:29] \"POST /mcp HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 06:32:29] \"POST /mcp HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Received MCP method: tools/call\n",
            "üì• Received MCP method: tools/list\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü§ñ ROUTER RESPONSE:\n",
            "Okay, I have retrieved Charlie Brown's information for you.\n",
            "\n",
            "Here are the details:\n",
            "\n",
            "*   **ID:** 5\n",
            "*   **Name:** Charlie Brown\n",
            "*   **Email:** charlie.brown@email.com\n",
            "*   **Phone:** +1-555-0105\n",
            "*   **Status:** active\n",
            "*   **Created At:** 2025-11-18 06:23:56\n",
            "*   **Updated At:** 2025-11-18 06:23:56\n",
            "\n",
            "How can I assist Charlie further today?\n",
            "\n",
            "======================================================================\n",
            "üë§ USER: I'm customer 5 and need help upgrading my account\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 06:32:33] \"POST /mcp HTTP/1.1\" 200 -\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Received MCP method: tools/list\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 06:32:35] \"POST /mcp HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 06:32:35] \"POST /mcp HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Received MCP method: tools/call\n",
            "üì• Received MCP method: tools/list\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü§ñ ROUTER RESPONSE:\n",
            "Thank you for reaching out! I understand you need help upgrading your account.\n",
            "\n",
            "A high-priority ticket (ID: 26) has been created for your account upgrade request. Our team will review your request and reach out to you directly to assist with the upgrade process.\n",
            "\n",
            "======================================================================\n",
            "üë§ USER: Show me all active customers who have open tickets\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 06:32:39] \"POST /mcp HTTP/1.1\" 200 -\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Received MCP method: tools/list\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 06:32:44] \"POST /mcp HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü§ñ ROUTER RESPONSE:\n",
            "I understand you're looking for active customers with open tickets.\n",
            "\n",
            "However, the customer data system can only filter customers by their status (active or disabled). It cannot filter them by whether they have open tickets.\n",
            "\n",
            "I can provide a list of all active customers if you'd like. Please let me know how you'd like to proceed!\n",
            "\n",
            "======================================================================\n",
            "üë§ USER: I've been charged twice, please refund immediately!\n",
            "======================================================================\n",
            "üì• Received MCP method: tools/list\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "ERROR:google_adk.google.adk.a2a.executor.a2a_agent_executor:Error handling A2A request: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/a2a/executor/a2a_agent_executor.py\", line 149, in execute\n",
            "    await self._handle_request(context, event_queue)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/a2a/executor/a2a_agent_executor.py\", line 215, in _handle_request\n",
            "    async for adk_event in runner.run_async(**run_args):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/runners.py\", line 233, in run_async\n",
            "    async for event in self._exec_with_plugin(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/runners.py\", line 274, in _exec_with_plugin\n",
            "    async for event in execute_fn(invocation_context):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/runners.py\", line 230, in execute\n",
            "    async for event in ctx.agent.run_async(ctx):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/agents/base_agent.py\", line 206, in run_async\n",
            "    async for event in self._run_async_impl(ctx):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/agents/llm_agent.py\", line 285, in _run_async_impl\n",
            "    async for event in self._llm_flow.run_async(ctx):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 290, in run_async\n",
            "    async for event in self._run_one_step_async(invocation_context):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 318, in _run_one_step_async\n",
            "    async for llm_response in self._call_llm_async(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 567, in _call_llm_async\n",
            "    async for llm_response in self._run_and_handle_error(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 723, in _run_and_handle_error\n",
            "    raise model_error\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 707, in _run_and_handle_error\n",
            "    async for response in response_generator:\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/models/google_llm.py\", line 198, in generate_content_async\n",
            "    response = await self.api_client.aio.models.generate_content(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/genai/models.py\", line 7033, in generate_content\n",
            "    response = await self._generate_content(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/genai/models.py\", line 5839, in _generate_content\n",
            "    response = await self._api_client.async_request(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/genai/_api_client.py\", line 1376, in async_request\n",
            "    result = await self._async_request(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/genai/_api_client.py\", line 1309, in _async_request\n",
            "    return await self._async_retry(  # type: ignore[no-any-return]\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/genai/_api_client.py\", line 1254, in _async_request_once\n",
            "    await errors.APIError.raise_for_async_response(response)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/genai/errors.py\", line 188, in raise_for_async_response\n",
            "    await cls.raise_error_async(status_code, response_json, response)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/genai/errors.py\", line 212, in raise_error_async\n",
            "    raise ServerError(status_code, response_json, response)\n",
            "google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü§ñ ROUTER RESPONSE:\n",
            "503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
            "\n",
            "======================================================================\n",
            "üë§ USER: Update my email to new_email@example.com and show my ticket history for customer 5\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 06:32:47] \"POST /mcp HTTP/1.1\" 200 -\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Received MCP method: tools/list\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:google_adk.google.adk.a2a.executor.a2a_agent_executor:Error handling A2A request: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/a2a/executor/a2a_agent_executor.py\", line 149, in execute\n",
            "    await self._handle_request(context, event_queue)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/a2a/executor/a2a_agent_executor.py\", line 215, in _handle_request\n",
            "    async for adk_event in runner.run_async(**run_args):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/runners.py\", line 233, in run_async\n",
            "    async for event in self._exec_with_plugin(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/runners.py\", line 274, in _exec_with_plugin\n",
            "    async for event in execute_fn(invocation_context):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/runners.py\", line 230, in execute\n",
            "    async for event in ctx.agent.run_async(ctx):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/agents/base_agent.py\", line 206, in run_async\n",
            "    async for event in self._run_async_impl(ctx):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/agents/llm_agent.py\", line 285, in _run_async_impl\n",
            "    async for event in self._llm_flow.run_async(ctx):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 290, in run_async\n",
            "    async for event in self._run_one_step_async(invocation_context):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 318, in _run_one_step_async\n",
            "    async for llm_response in self._call_llm_async(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 567, in _call_llm_async\n",
            "    async for llm_response in self._run_and_handle_error(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 723, in _run_and_handle_error\n",
            "    raise model_error\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 707, in _run_and_handle_error\n",
            "    async for response in response_generator:\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/models/google_llm.py\", line 198, in generate_content_async\n",
            "    response = await self.api_client.aio.models.generate_content(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/genai/models.py\", line 7021, in generate_content\n",
            "    return await self._generate_content(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/genai/models.py\", line 5839, in _generate_content\n",
            "    response = await self._api_client.async_request(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/genai/_api_client.py\", line 1376, in async_request\n",
            "    result = await self._async_request(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/genai/_api_client.py\", line 1309, in _async_request\n",
            "    return await self._async_retry(  # type: ignore[no-any-return]\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/genai/_api_client.py\", line 1254, in _async_request_once\n",
            "    await errors.APIError.raise_for_async_response(response)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/genai/errors.py\", line 188, in raise_for_async_response\n",
            "    await cls.raise_error_async(status_code, response_json, response)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/genai/errors.py\", line 212, in raise_error_async\n",
            "    raise ServerError(status_code, response_json, response)\n",
            "google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
            "ERROR:google_adk.google.adk.a2a.executor.a2a_agent_executor:Error handling A2A request: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10, model: gemini-2.5-flash\\nPlease retry in 9.49460296s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '9s'}]}}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/a2a/executor/a2a_agent_executor.py\", line 149, in execute\n",
            "    await self._handle_request(context, event_queue)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/a2a/executor/a2a_agent_executor.py\", line 215, in _handle_request\n",
            "    async for adk_event in runner.run_async(**run_args):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/runners.py\", line 233, in run_async\n",
            "    async for event in self._exec_with_plugin(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/runners.py\", line 274, in _exec_with_plugin\n",
            "    async for event in execute_fn(invocation_context):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/runners.py\", line 230, in execute\n",
            "    async for event in ctx.agent.run_async(ctx):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/agents/base_agent.py\", line 206, in run_async\n",
            "    async for event in self._run_async_impl(ctx):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/agents/llm_agent.py\", line 285, in _run_async_impl\n",
            "    async for event in self._llm_flow.run_async(ctx):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 290, in run_async\n",
            "    async for event in self._run_one_step_async(invocation_context):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 318, in _run_one_step_async\n",
            "    async for llm_response in self._call_llm_async(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 567, in _call_llm_async\n",
            "    async for llm_response in self._run_and_handle_error(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 723, in _run_and_handle_error\n",
            "    raise model_error\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 707, in _run_and_handle_error\n",
            "    async for response in response_generator:\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/adk/models/google_llm.py\", line 198, in generate_content_async\n",
            "    response = await self.api_client.aio.models.generate_content(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/genai/models.py\", line 7033, in generate_content\n",
            "    response = await self._generate_content(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/genai/models.py\", line 5839, in _generate_content\n",
            "    response = await self._api_client.async_request(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/genai/_api_client.py\", line 1376, in async_request\n",
            "    result = await self._async_request(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/genai/_api_client.py\", line 1309, in _async_request\n",
            "    return await self._async_retry(  # type: ignore[no-any-return]\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/genai/_api_client.py\", line 1254, in _async_request_once\n",
            "    await errors.APIError.raise_for_async_response(response)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/genai/errors.py\", line 188, in raise_for_async_response\n",
            "    await cls.raise_error_async(status_code, response_json, response)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/genai/errors.py\", line 210, in raise_error_async\n",
            "    raise ClientError(status_code, response_json, response)\n",
            "google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10, model: gemini-2.5-flash\\nPlease retry in 9.49460296s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '9s'}]}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü§ñ ROUTER RESPONSE:\n",
            "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10, model: gemini-2.5-flash\\nPlease retry in 9.49460296s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '9s'}]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† Conclusion\n",
        "\n",
        "During this project, I learned how A2A communication enables multiple specialized agents to collaborate on a single user request. Designing a Router Agent taught me how an orchestrator can interpret intent, delegate subtasks, and synchronize results. Implementing an MCP server deepened my understanding of tool schemas, JSON-RPC message handling, SSE responses, and backend integration with SQLite.\n",
        "\n",
        "### The biggest challenges were:\n",
        "\n",
        "- Managing asynchronous A2A servers inside a Colab environment\n",
        "\n",
        "- Aligning agent interfaces between ADK and A2A-SDK\n",
        "\n",
        "- Ensuring MCP tools were reliable, well-typed, and transaction-safe\n",
        "\n",
        "- Debugging complex multi-agent chains where data passed between agents could easily become inconsistent\n",
        "\n",
        "Overall, this assignment provided real-world experience in building production-style multi-agent architectures, coordinating agent workflows, and integrating structured tool calls inside a unified customer service automation pipeline."
      ],
      "metadata": {
        "id": "vhfFkHc5sHrN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CWWPPNbMk6de"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "flowchart TD\n",
        "\n",
        "%% =========================\n",
        "%%   USER & ROUTER LAYER\n",
        "%% =========================\n",
        "User([\"üë§ User Query\"]) --> R1[\"üß≠ Router Agent<br/>(A2A Orchestrator)\"]\n",
        "\n",
        "%% =========================\n",
        "%%   SPECIALIST AGENTS\n",
        "%% =========================\n",
        "subgraph A2A[\"A2A Multi-Agent Layer\"]\n",
        "    direction LR\n",
        "\n",
        "    CDA[\"üìò Customer Data Agent<br/>(A2A Server: 11020)<br/>Uses MCP Tools\"]\n",
        "    SA[\"üí¨ Support Agent<br/>(A2A Server: 11021)<br/>General Support\"]\n",
        "\n",
        "end\n",
        "\n",
        "R1 -->|Task allocation / Delegation| CDA\n",
        "R1 -->|Escalation / Support Request| SA\n",
        "\n",
        "%% =========================\n",
        "%%   MCP SERVER + DB\n",
        "%% =========================\n",
        "subgraph MCP[\"üß© MCP Server<br/>(JSON-RPC + SSE)\"]\n",
        "    MCP_API[\"üõ† MCP Tools<br/>\n",
        "    - get_customer<br/>\n",
        "    - list_customers<br/>\n",
        "    - update_customer<br/>\n",
        "    - create_ticket<br/>\n",
        "    - get_customer_history\"]\n",
        "end\n",
        "\n",
        "CDA -->|MCP Tool Calls| MCP_API\n",
        "\n",
        "%% =========================\n",
        "%%   DATABASE\n",
        "%% =========================\n",
        "subgraph DB[\"üóÑ SQLite Database (support.db)\"]\n",
        "    CUSTOMERS[\"üìÑ customers table\"]\n",
        "    TICKETS[\"üìÑ tickets table\"]\n",
        "end\n",
        "\n",
        "MCP_API --> CUSTOMERS\n",
        "MCP_API --> TICKETS\n",
        "\n",
        "%% =========================\n",
        "%%   RESPONSE FLOW\n",
        "%% =========================\n",
        "SA -->|Support summary / resolution| R1\n",
        "CDA -->|Customer data / Ticket data| R1\n",
        "R1 -->|Final Answer| User\n"
      ],
      "metadata": {
        "id": "p6w3o9vXwuOF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a **clear, correct, end-to-end architecture diagram** (Mermaid) that matches your actual system exactly ‚Äî MCP server, 3 A2A agents, communication flows, and user queries.\n",
        "\n",
        "Copy-paste directly into GitHub README and it will render perfectly.\n",
        "\n",
        "---\n",
        "\n",
        "# üìå **Multi-Agent Customer Service System ‚Äì Architecture Diagram (Mermaid)**\n",
        "\n",
        "```mermaid\n",
        "flowchart TD\n",
        "\n",
        "%% =========================\n",
        "%%   USER & ROUTER LAYER\n",
        "%% =========================\n",
        "User([\"üë§ User Query\"]) --> R1[\"üß≠ Router Agent<br/>(A2A Orchestrator)\"]\n",
        "\n",
        "%% =========================\n",
        "%%   SPECIALIST AGENTS\n",
        "%% =========================\n",
        "subgraph A2A[\"A2A Multi-Agent Layer\"]\n",
        "    direction LR\n",
        "\n",
        "    CDA[\"üìò Customer Data Agent<br/>(A2A Server: 11020)<br/>Uses MCP Tools\"]\n",
        "    SA[\"üí¨ Support Agent<br/>(A2A Server: 11021)<br/>General Support\"]\n",
        "\n",
        "end\n",
        "\n",
        "R1 -->|Task allocation / Delegation| CDA\n",
        "R1 -->|Escalation / Support Request| SA\n",
        "\n",
        "%% =========================\n",
        "%%   MCP SERVER + DB\n",
        "%% =========================\n",
        "subgraph MCP[\"üß© MCP Server<br/>(JSON-RPC + SSE)\"]\n",
        "    MCP_API[\"üõ† MCP Tools<br/>\n",
        "    - get_customer<br/>\n",
        "    - list_customers<br/>\n",
        "    - update_customer<br/>\n",
        "    - create_ticket<br/>\n",
        "    - get_customer_history\"]\n",
        "end\n",
        "\n",
        "CDA -->|MCP Tool Calls| MCP_API\n",
        "\n",
        "%% =========================\n",
        "%%   DATABASE\n",
        "%% =========================\n",
        "subgraph DB[\"üóÑ SQLite Database (support.db)\"]\n",
        "    CUSTOMERS[\"üìÑ customers table\"]\n",
        "    TICKETS[\"üìÑ tickets table\"]\n",
        "end\n",
        "\n",
        "MCP_API --> CUSTOMERS\n",
        "MCP_API --> TICKETS\n",
        "\n",
        "%% =========================\n",
        "%%   RESPONSE FLOW\n",
        "%% =========================\n",
        "SA -->|Support summary / resolution| R1\n",
        "CDA -->|Customer data / Ticket data| R1\n",
        "R1 -->|Final Answer| User\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# ‚úÖ **What this diagram shows**\n",
        "\n",
        "### **1. User Message Flow**\n",
        "\n",
        "User ‚Üí Router Agent ‚Üí (sub-agents) ‚Üí Router ‚Üí User\n",
        "\n",
        "### **2. A2A Agent Interactions**\n",
        "\n",
        "* Router assigns work\n",
        "* Customer Data Agent pulls real data via MCP\n",
        "* Support Agent handles natural-language support\n",
        "* Router synthesizes final response\n",
        "\n",
        "### **3. MCP integration**\n",
        "\n",
        "Customer Data Agent uses:\n",
        "\n",
        "* get_customer\n",
        "* list_customers\n",
        "* update_customer\n",
        "* create_ticket\n",
        "* get_customer_history\n",
        "\n",
        "All routed to:\n",
        "\n",
        "* SQLite `customers` table\n",
        "* SQLite `tickets` table\n",
        "\n",
        "### **4. Full system layering**\n",
        "\n",
        "‚úî User layer\n",
        "‚úî A2A layer\n",
        "‚úî MCP layer\n",
        "‚úî Database layer\n",
        "\n",
        "Everything is accurately represented.\n"
      ],
      "metadata": {
        "id": "KZ196ZgkwyTC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Support Agent‚Äôs role is simple**:\n",
        "\n",
        "### **Short answer:**\n",
        "\n",
        "The **Support Agent** handles all **general customer support conversations**, uses the **context provided by the Router and Customer Data Agent**, and gives **friendly, actionable help** ‚Äî **but it never calls the MCP server directly**.\n",
        "\n",
        "It acts like a **frontline support representative** inside your multi-agent system."
      ],
      "metadata": {
        "id": "TrR8lpdKxDg7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "* Support Agent **handles general customer support**\n",
        "* Support Agent **never touches the MCP database directly**\n",
        "* Support Agent **waits for the Router/Data Agent to provide customer context**\n",
        "* Support Agent **escalates complex issues when needed**\n",
        "\n",
        "My current Support Agent matches these requirements perfectly.\n"
      ],
      "metadata": {
        "id": "TyPe-HmbxPd_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3gvyQANxwu60"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}